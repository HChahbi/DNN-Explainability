{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5deb7dbc-c7b1-4e8b-adb1-9b2e5c34b646",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-17T15:34:19.942421Z",
     "iopub.status.busy": "2022-09-17T15:34:19.941417Z",
     "iopub.status.idle": "2022-09-17T15:34:22.864311Z",
     "shell.execute_reply": "2022-09-17T15:34:22.862304Z",
     "shell.execute_reply.started": "2022-09-17T15:34:19.942421Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dde0c60-5018-401e-a19d-e1fb053ce05c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-07T16:11:12.411148Z",
     "iopub.status.busy": "2022-09-07T16:11:12.411148Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATASET_COLUMNS = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "DATASET_ENCODING = \"ISO-8859-1\"\n",
    "data = pd.read_csv(\n",
    "    \"gs://data-reasearch/data.csv\", encoding=DATASET_ENCODING, names=DATASET_COLUMNS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5555f1dd-81c1-4a7e-9d88-a4aba71653d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.target = data.target.replace(4, 1)\n",
    "data.text.apply(lambda x: len(x.split())).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2c4cdb-0eab-4770-9b1a-f8677771bb2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import ClassLabel, Dataset\n",
    "\n",
    "data_set = Dataset.from_pandas(data)\n",
    "data_set = data_set.cast_column(\"target\", ClassLabel(num_classes=2, names=[0, 1]))\n",
    "data_set = data_set.train_test_split(\n",
    "    test_size=0.2, stratify_by_column=\"target\", seed=1234\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ddb452e-4580-48fe-8689-8c62586e4112",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-21T19:05:57.505271Z",
     "iopub.status.busy": "2022-08-21T19:05:57.505271Z",
     "iopub.status.idle": "2022-08-21T19:06:03.506168Z",
     "shell.execute_reply": "2022-08-21T19:06:03.505167Z",
     "shell.execute_reply.started": "2022-08-21T19:05:57.505271Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "687b3370f28a4890999ae56fb2ced50b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/32 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "45968943"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set[\"test\"].to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de534833-5fb7-4e5f-a096-ac16110ccb38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5953a1cf-3bdb-4571-acad-12b7ecee7985",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-21T18:40:49.344387Z",
     "iopub.status.busy": "2022-08-21T18:40:49.343383Z",
     "iopub.status.idle": "2022-08-21T18:40:49.366392Z",
     "shell.execute_reply": "2022-08-21T18:40:49.365391Z",
     "shell.execute_reply.started": "2022-08-21T18:40:49.343383Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\",\n",
       "       \"is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!\",\n",
       "       '@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds',\n",
       "       'my whole body feels itchy and like its on fire ',\n",
       "       \"@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there. \"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head().text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d02c6f22-043a-4dbc-8222-1184efe75ed2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-21T18:26:35.714399Z",
     "iopub.status.busy": "2022-08-21T18:26:35.713390Z",
     "iopub.status.idle": "2022-08-21T18:26:45.327336Z",
     "shell.execute_reply": "2022-08-21T18:26:45.326341Z",
     "shell.execute_reply.started": "2022-08-21T18:26:35.714399Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('to', 552962),\n",
       " ('I', 496619),\n",
       " ('the', 487501),\n",
       " ('a', 366212),\n",
       " ('my', 280025),\n",
       " ('and', 275263),\n",
       " ('i', 250016),\n",
       " ('is', 217693),\n",
       " ('you', 213871),\n",
       " ('for', 209801),\n",
       " ('in', 202294),\n",
       " ('of', 179554),\n",
       " ('it', 171812),\n",
       " ('on', 154365),\n",
       " ('have', 132249),\n",
       " ('so', 125155),\n",
       " ('me', 122509),\n",
       " ('that', 118685),\n",
       " ('with', 110843),\n",
       " ('be', 108069),\n",
       " ('but', 106272),\n",
       " ('at', 102196),\n",
       " (\"I'm\", 99559),\n",
       " ('was', 99140),\n",
       " ('just', 96284),\n",
       " ('not', 88110),\n",
       " ('this', 77810),\n",
       " ('get', 76734),\n",
       " ('like', 73302),\n",
       " ('are', 72568),\n",
       " ('up', 70007),\n",
       " ('all', 67901),\n",
       " ('-', 67079),\n",
       " ('out', 67030),\n",
       " ('go', 62969),\n",
       " ('your', 60854),\n",
       " ('good', 59775),\n",
       " ('day', 55748),\n",
       " ('do', 54628),\n",
       " ('from', 54182),\n",
       " ('got', 53871),\n",
       " ('now', 53591),\n",
       " ('going', 53236),\n",
       " ('love', 50051),\n",
       " ('no', 49622),\n",
       " ('about', 46708),\n",
       " ('work', 45913),\n",
       " ('will', 45898),\n",
       " ('back', 44033),\n",
       " ('u', 43568)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(\" \".join(data.text.to_list()).split()).most_common(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338ac72d-bc78-4fe0-9ff5-9714e6eec5bd",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c44abdff-8544-40c6-8a13-aeae790aacdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:33:20.594174Z",
     "iopub.status.busy": "2022-08-02T18:33:20.593171Z",
     "iopub.status.idle": "2022-08-02T18:33:37.437252Z",
     "shell.execute_reply": "2022-08-02T18:33:37.435268Z",
     "shell.execute_reply.started": "2022-08-02T18:33:20.594174Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer, models, normalizers, pre_tokenizers, trainers\n",
    "\n",
    "tokenizer = Tokenizer(models.WordLevel(unk_token=\"<unk>\"))\n",
    "tokenizer.normalizer = normalizers.Sequence(\n",
    "    [\n",
    "        normalizers.NFD(),\n",
    "        normalizers.StripAccents(),\n",
    "        normalizers.Strip(),\n",
    "        normalizers.Lowercase(),\n",
    "        # normalizers.Replace(),\n",
    "    ]\n",
    ")\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.Sequence(\n",
    "    [pre_tokenizers.Whitespace(), pre_tokenizers.Punctuation(), pre_tokenizers.Digits()]\n",
    ")\n",
    "trainer = trainers.WordLevelTrainer(\n",
    "    vocab_size=10000, show_progress=True, special_tokens=[\"<unk>\", \"<pad>\"]\n",
    ")\n",
    "tokenizer.train_from_iterator(data.text.to_list(), trainer=trainer)\n",
    "tokenizer.enable_padding(pad_token=\"<pad>\", pad_id=tokenizer.token_to_id(\"<pad>\"))\n",
    "tokenizer.enable_truncation(max_length=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc687c17-e2f9-41ea-97df-a5829f5b6594",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T18:33:42.171399Z",
     "iopub.status.busy": "2022-08-02T18:33:42.171399Z",
     "iopub.status.idle": "2022-08-02T18:33:42.216390Z",
     "shell.execute_reply": "2022-08-02T18:33:42.214403Z",
     "shell.execute_reply.started": "2022-08-02T18:33:42.171399Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fc7a2368-7dfc-4d5d-b8e5-85d6ee078d53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T18:56:46.331739Z",
     "iopub.status.busy": "2022-08-01T18:56:46.330713Z",
     "iopub.status.idle": "2022-08-01T18:56:46.352701Z",
     "shell.execute_reply": "2022-08-01T18:56:46.351691Z",
     "shell.execute_reply.started": "2022-08-01T18:56:46.331739Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"Hello how are you r u fine\").ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "daf79cab-2ef2-4376-9d5e-756e54a9feed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T18:56:47.116708Z",
     "iopub.status.busy": "2022-08-01T18:56:47.115738Z",
     "iopub.status.idle": "2022-08-01T18:56:47.139702Z",
     "shell.execute_reply": "2022-08-01T18:56:47.137723Z",
     "shell.execute_reply.started": "2022-08-01T18:56:47.116708Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'length': None,\n",
       " 'pad_to_multiple_of': None,\n",
       " 'pad_id': 1,\n",
       " 'pad_token': '<pad>',\n",
       " 'pad_type_id': 0,\n",
       " 'direction': 'right'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2fb25e0c-e917-4db8-a988-d12213a68c50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T19:01:02.822304Z",
     "iopub.status.busy": "2022-08-01T19:01:02.821300Z",
     "iopub.status.idle": "2022-08-01T19:01:02.833303Z",
     "shell.execute_reply": "2022-08-01T19:01:02.832293Z",
     "shell.execute_reply.started": "2022-08-01T19:01:02.821300Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[0, 0, 1, 1, 1], [6, 0, 0, 1, 1], [0, 0, 5, 7, 4], [0, 8, 0, 0, 0], [0, 0, 0, 9, 2]], 'token_type_ids': [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 0, 0, 0], [1, 1, 1, 0, 0], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "fast_tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_object=tokenizer, max_len=5, pad_token=\"<pad>\"\n",
    ")\n",
    "fast_tokenizer(data, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afe4c6a3-d059-4bea-b429-8024b33d5f69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T18:07:09.345329Z",
     "iopub.status.busy": "2022-08-01T18:07:09.345329Z",
     "iopub.status.idle": "2022-08-01T18:07:09.348332Z",
     "shell.execute_reply": "2022-08-01T18:07:09.348332Z",
     "shell.execute_reply.started": "2022-08-01T18:07:09.345329Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer.padding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa24a33-9a36-4d51-820e-60fa0f9103aa",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf2f98a-a369-4748-bf6b-1d5775391e59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-17T15:34:34.446703Z",
     "iopub.status.busy": "2022-09-17T15:34:34.446703Z",
     "iopub.status.idle": "2022-09-17T15:34:39.304184Z",
     "shell.execute_reply": "2022-09-17T15:34:39.301176Z",
     "shell.execute_reply.started": "2022-09-17T15:34:34.446703Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "class TweetDataSet(Dataset):\n",
    "    def __init__(self, data_dir: str = \"./\"):\n",
    "        super(TweetDataSet, self).__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.dims = (3, 32, 32)\n",
    "        self.num_classes = 10\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # download\n",
    "        CIFAR10(self.data_dir, train=True, download=True)\n",
    "        CIFAR10(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            cifar_full = CIFAR10(self.data_dir, train=True, transform=self.transform)\n",
    "            self.cifar_train, self.cifar_val = random_split(cifar_full, [45000, 5000])\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.cifar_test = CIFAR10(\n",
    "                self.data_dir, train=False, transform=self.transform\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.cifar_train, batch_size=BATCH_SIZE)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.cifar_val, batch_size=BATCH_SIZE)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.cifar_test, batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "def collator(batch, tokenizer):\n",
    "    text = [item for item in batch]\n",
    "    out_tokenizer = fast_tokenizer(text, truncation=True, padding=True)\n",
    "    input_ids = torch.LongTensor(out_tokenizer[\"input_ids\"])\n",
    "    attention_mask = torch.LongTensor(out_tokenizer[\"attention_mask\"])\n",
    "    return out_tokenizer\n",
    "\n",
    "\n",
    "next(\n",
    "    iter(\n",
    "        DataLoader(\n",
    "            data,\n",
    "            batch_size=2,\n",
    "            shuffle=True,\n",
    "            collate_fn=lambda x: collator(x, tokenizer),\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f0f642-4a43-4ae1-bc6f-d873f19250d8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63aad3a9-d3fc-42f8-9a6c-3a1e801b312e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-17T15:34:43.341711Z",
     "iopub.status.busy": "2022-09-17T15:34:43.341711Z",
     "iopub.status.idle": "2022-09-17T15:34:49.738056Z",
     "shell.execute_reply": "2022-09-17T15:34:49.736041Z",
     "shell.execute_reply.started": "2022-09-17T15:34:43.341711Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from pytorch_lightning.core.module import LightningModule\n",
    "from torchmetrics import Accuracy\n",
    "from transformers import AdamW, AutoModel, get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "class TweetCatModel(LightningModule):\n",
    "    def __init__(\n",
    "        self, hidden_dim, dropout_clf, output_dim, learning_rate, max_epochs, lm_path\n",
    "    ):\n",
    "        super(TweetCatModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout_clf = dropout_clf\n",
    "        self.output_dim = output_dim\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_epochs = max_epochs\n",
    "        self.lm = AutoModel.from_pretrained(lm_path)\n",
    "        lm_output = self.lm.pooler.dense.out_features\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(lm_output, hidden_dim),\n",
    "            nn.Dropout(dropout_clf),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "        )\n",
    "        # Define metrics used during training\n",
    "        self.metric = Accuracy()\n",
    "        self.eval_metric = Accuracy()\n",
    "        self.test_metric = Accuracy()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        lm_output = self.lm(input_ids, attention_mask).pooler_output\n",
    "        logits = self.classifier(lm_output)\n",
    "        return logits\n",
    "\n",
    "    def compute_loss(self, logits, labels):\n",
    "        return self.loss_fn(logits, labels)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        tagger_params = filter(lambda p: p.requires_grad, self.parameters())\n",
    "        optimizer = AdamW(tagger_params, lr=self.learning_rate)\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=int(self.max_epochs / 10),\n",
    "            num_training_steps=self.max_epochs,\n",
    "        )\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def decode(self, scores):\n",
    "        # scores (float) [batch_size, output_dim]\n",
    "        res = torch.argmax(scores, axis=1)\n",
    "        return res\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs_ids, attenstion_mask, label_ids = batch\n",
    "        logits = self(inputs_ids, attenstion_mask)\n",
    "        loss = self.compute_loss(logits, label_ids)\n",
    "        preds = self.decode(logits)\n",
    "        self.metric(preds, label_ids)\n",
    "        # Log metrics into logger\n",
    "        self.log(\"train_loss\", loss, on_epoch=True, on_step=False)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs_ids, attenstion_mask, label_ids = batch\n",
    "        logits = self(inputs_ids, attenstion_mask)\n",
    "        loss = self.compute_loss(logits, label_ids)\n",
    "        preds = self.decode(logits)\n",
    "        self.eval_metric(preds, label_ids)\n",
    "        # Log metrics into logger\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, on_step=False)\n",
    "        return loss\n",
    "\n",
    "    def validation_epoch_end(self, outs):\n",
    "        self.log(\"val_acc\", self.eval_metric.compute())\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        inputs_ids, attenstion_mask, label_ids = batch\n",
    "        logits = self(inputs_ids, attenstion_mask)\n",
    "        loss = self.compute_loss(logits, label_ids)\n",
    "        preds = self.decode(logits)\n",
    "        self.test_metric(preds, label_ids)\n",
    "        # Log metrics into logger\n",
    "        self.log(\"test_loss\", loss, on_epoch=True, on_step=False)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b89897c1-98df-4e57-8cf5-eea24d80e261",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-17T15:34:55.262055Z",
     "iopub.status.busy": "2022-09-17T15:34:55.262055Z",
     "iopub.status.idle": "2022-09-17T15:35:05.603763Z",
     "shell.execute_reply": "2022-09-17T15:35:05.602762Z",
     "shell.execute_reply.started": "2022-09-17T15:34:55.262055Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-xlm-roberta-base-sentiment were not used when initializing XLMRobertaModel: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base-sentiment and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import yaml\n",
    "\n",
    "\n",
    "def load_checkpoint_model(path, model_name):\n",
    "    path_params = os.path.join(path, \"hparams.yaml\")\n",
    "    path_model = os.path.join(path, model_name)\n",
    "    with open(path_params) as file:\n",
    "        model_params = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "    return TweetCatModel.load_from_checkpoint(\n",
    "        checkpoint_path=path_model, hparams_file=path_params\n",
    "    )\n",
    "\n",
    "\n",
    "retrained_model = load_checkpoint_model(\"./model\", \"epoch=2-step=34000.ckpt\")\n",
    "retrained_model.eval()\n",
    "retrained_model.zero_grad()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aae4da9-d74c-4923-b432-f4a9eebafbbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-15T23:07:59.959483Z",
     "iopub.status.busy": "2022-09-15T23:07:59.959483Z",
     "iopub.status.idle": "2022-09-15T23:08:00.670985Z",
     "shell.execute_reply": "2022-09-15T23:08:00.669003Z",
     "shell.execute_reply.started": "2022-09-15T23:07:59.959483Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.nn.Softmax(dim=1)(model(torch.randn(100, 96)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f99a314-2bd4-43b8-910c-3667e2704471",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-17T15:35:37.447824Z",
     "iopub.status.busy": "2022-09-17T15:35:37.447824Z",
     "iopub.status.idle": "2022-09-17T15:35:52.986448Z",
     "shell.execute_reply": "2022-09-17T15:35:52.985453Z",
     "shell.execute_reply.started": "2022-09-17T15:35:37.447824Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel.save_pretrained(MODEL)\\n\\ntext = \"Good night 😊\"\\ntext = preprocess(text)\\nencoded_input = tokenizer(text, return_tensors=\\'pt\\')\\noutput = model(**encoded_input)\\nscores = output[0][0].detach().numpy()\\nscores = softmax(scores)'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModel,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "\n",
    "\n",
    "# Preprocess text (username and link placeholders)\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = \"@user\" if t.startswith(\"@\") and len(t) > 1 else t\n",
    "        t = \"http\" if t.startswith(\"http\") else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "\n",
    "MODEL = f\"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, padding=\"max_length\")\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "\n",
    "# PT\n",
    "#model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\"\"\"\n",
    "model.save_pretrained(MODEL)\n",
    "\n",
    "text = \"Good night 😊\"\n",
    "text = preprocess(text)\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d18eb68-26e2-41ea-a175-d472a83fa0be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-15T23:28:09.951842Z",
     "iopub.status.busy": "2022-09-15T23:28:09.951842Z",
     "iopub.status.idle": "2022-09-15T23:28:10.078861Z",
     "shell.execute_reply": "2022-09-15T23:28:10.078861Z",
     "shell.execute_reply.started": "2022-09-15T23:28:09.951842Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrained_model(\n",
    "    **tokenizer(\n",
    "        [\"I hate you\", \"I love you\"],\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=128,\n",
    "    )\n",
    ").argmax(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ab9716-6440-4442-a92f-831f481311e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c578142c-8f89-4031-a547-d090d3975ea5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-16T18:37:06.496294Z",
     "iopub.status.busy": "2022-09-16T18:37:06.496294Z",
     "iopub.status.idle": "2022-09-16T18:37:06.831291Z",
     "shell.execute_reply": "2022-09-16T18:37:06.829284Z",
     "shell.execute_reply.started": "2022-09-16T18:37:06.496294Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4012d4d4-4cba-4f78-a5fb-d76797284b7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-18T21:31:35.650786Z",
     "iopub.status.busy": "2022-09-18T21:31:35.649784Z",
     "iopub.status.idle": "2022-09-18T21:31:37.089751Z",
     "shell.execute_reply": "2022-09-18T21:31:37.087746Z",
     "shell.execute_reply.started": "2022-09-18T21:31:35.650786Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 0, 0, 1])\n",
      "tensor([1, 0, 0, 0, 1])\n",
      "Visualize attributions based on Gradients X Input\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>1 (0.99)</b></text></td><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>-1.27</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 79%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">                     </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> It                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  was                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 83%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  fantastic                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  performance                    </font></mark><mark style=\"background-color: hsl(0, 75%, 74%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  !                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">                     </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>0 (0.98)</b></text></td><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>-2.01</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 82%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">                     </font></mark><mark style=\"background-color: hsl(0, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> This                    </font></mark><mark style=\"background-color: hsl(0, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  is                    </font></mark><mark style=\"background-color: hsl(0, 75%, 71%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  a                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  bad                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  movie                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">                     </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">                     </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>0 (0.79)</b></text></td><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>-1.70</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">                     </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> I                    </font></mark><mark style=\"background-color: hsl(0, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  wake                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  up                    </font></mark><mark style=\"background-color: hsl(0, 75%, 79%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  late                    </font></mark><mark style=\"background-color: hsl(0, 75%, 71%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">                     </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">                     </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">                     </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>0 (0.99)</b></text></td><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>-1.48</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 74%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">                     </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> This                    </font></mark><mark style=\"background-color: hsl(0, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  guy                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  is                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  not                    </font></mark><mark style=\"background-color: hsl(0, 75%, 74%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  nice                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">                     </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">                     </font></mark></td><tr><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>1 (0.98)</b></text></td><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>-1.65</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 66%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">                     </font></mark><mark style=\"background-color: hsl(0, 75%, 84%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> This                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  woman                    </font></mark><mark style=\"background-color: hsl(0, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  is                    </font></mark><mark style=\"background-color: hsl(0, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">  beautiful                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">                     </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">                     </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\">                     </font></mark></td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from captum.attr import (\n",
    "    InternalInfluence,\n",
    "    LayerActivation,\n",
    "    LayerConductance,\n",
    "    LayerDeepLift,\n",
    "    LayerDeepLiftShap,\n",
    "    LayerFeatureAblation,\n",
    "    LayerGradCam,\n",
    "    LayerGradientShap,\n",
    "    LayerGradientXActivation,\n",
    "    LayerIntegratedGradients,\n",
    "    LayerLRP,\n",
    "    TokenReferenceBase,\n",
    ")\n",
    "from captum.attr import visualization as viz\n",
    "\n",
    "PAD_IND = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "token_reference = TokenReferenceBase(reference_token_idx=PAD_IND)\n",
    "lig = LayerGradientXActivation(\n",
    "    retrained_model, retrained_model.lm.embeddings, multiply_by_inputs=True)\n",
    "\n",
    "\n",
    "def get_tokens_from_offsets(text, offsets):\n",
    "    return [text[start:end] for start, end in offsets]\n",
    "\n",
    "\n",
    "sentence_list = [\n",
    "    \"It was a fantastic performance !\",\n",
    "    \"This is a bad movie\",\n",
    "    \"I wake up late\",\n",
    "    \"This guy is not nice\",\n",
    "    \"This woman is beautiful\"\n",
    "]\n",
    "target = torch.LongTensor([1, 0, 0, 0, 1])\n",
    "text = [preprocess(s) for s in sentence_list]\n",
    "tokenized = tokenizer(text, truncation=True, padding=True, return_offsets_mapping=True)\n",
    "input_indices = torch.LongTensor(tokenized.input_ids)\n",
    "input_emb = retrained_model.lm.embeddings(input_indices)\n",
    "attention_mask = torch.LongTensor(tokenized.attention_mask)\n",
    "tokens = list(map(get_tokens_from_offsets, text, tokenized.offset_mapping))\n",
    "# predict\n",
    "pred = retrained_model(input_indices, attention_mask)\n",
    "pred_prob = torch.softmax(pred, dim=1)\n",
    "pred_ind = pred.argmax(dim=1)\n",
    "print(pred_ind)\n",
    "\n",
    "# generate reference indices for each sample\n",
    "reference_indices = torch.full(size=(input_indices.shape), fill_value=PAD_IND)\n",
    "# compute attributions and approximation delta using layer integrated gradients*\n",
    "print(target)\n",
    "attributions = lig.attribute(\n",
    "    inputs=input_indices,\n",
    "    #baselines=reference_indices,\n",
    "    target=target,\n",
    "    additional_forward_args=attention_mask,\n",
    "    #return_convergence_delta=True\n",
    "    # verbose=True\n",
    ")\n",
    "attributions = attributions.sum(dim=-1)\n",
    "attributions = attributions / torch.norm(attributions, dim=1).unsqueeze(1)\n",
    "vis = []\n",
    "\n",
    "for i in range(len(sentence_list)):\n",
    "    vis.append(\n",
    "        viz.VisualizationDataRecord(\n",
    "            word_attributions=attributions[i],\n",
    "            pred_prob=pred_prob[i].max(),\n",
    "            pred_class=pred_ind[i],\n",
    "            true_class=target[i],\n",
    "            attr_class=str(target[i].item()),\n",
    "            attr_score=attributions.sum(dim=1)[i],\n",
    "            raw_input_ids=tokens[i],\n",
    "            convergence_score=delta[i],\n",
    "        )\n",
    "    )\n",
    "print(\"Visualize attributions based on Gradients X Input\")\n",
    "_ = viz.visualize_text(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "14565a8b-1295-4983-938c-f47da35f97ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-21T19:26:36.215777Z",
     "iopub.status.busy": "2022-08-21T19:26:36.215777Z",
     "iopub.status.idle": "2022-08-21T19:26:36.225768Z",
     "shell.execute_reply": "2022-08-21T19:26:36.224754Z",
     "shell.execute_reply.started": "2022-08-21T19:26:36.215777Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def chunks(data, chunk_size):\n",
    "    for i in range(0, len(data), chunk_size):\n",
    "        yield data[i : i + chunk_size]\n",
    "\n",
    "\n",
    "def predict(data, model, tokenizer, chunk_size=64, return_confidence=False):\n",
    "    len_data = len(data)\n",
    "    data_chunks = chunks(list(data.text), chunk_size)\n",
    "    res = []\n",
    "    for chunk in tqdm(data_chunks, total=int(len_data / chunk_size)):\n",
    "        text = [preprocess(example) for example in chunk]\n",
    "        out_tokenizer = tokenizer(text, truncation=True, padding=True)\n",
    "        input_ids = torch.LongTensor(out_tokenizer[\"input_ids\"])\n",
    "        attention_mask = torch.LongTensor(out_tokenizer[\"attention_mask\"])\n",
    "        scores = model(input_ids, attention_mask).argmax(dim=1)\n",
    "        res += scores\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ff5e55-5582-4ae6-b81e-a574687bd9dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-21T19:26:37.157904Z",
     "iopub.status.busy": "2022-08-21T19:26:37.157904Z",
     "iopub.status.idle": "2022-08-21T19:26:53.749401Z",
     "shell.execute_reply": "2022-08-21T19:26:53.748400Z",
     "shell.execute_reply.started": "2022-08-21T19:26:37.157904Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test.csv\")\n",
    "predict(test, retrained_model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3822f963-0585-428c-8447-6df14919b969",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-21T14:28:49.482533Z",
     "iopub.status.busy": "2022-08-21T14:28:49.481537Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# encoded_input = tokenizer([\"I hate you\", \"I love you\"], return_tensors='pt', truncation=True, padding=True, max_length=128)\n",
    "model(\n",
    "    **tokenizer(\n",
    "        [\"I hate you\", \"I love you\"],\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=128,\n",
    "    )\n",
    ").logits[:, [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "de096c5f-5ce9-4b15-9471-ded341ab2959",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-21T13:55:43.646811Z",
     "iopub.status.busy": "2022-08-21T13:55:43.645806Z",
     "iopub.status.idle": "2022-08-21T13:55:54.376444Z",
     "shell.execute_reply": "2022-08-21T13:55:54.375459Z",
     "shell.execute_reply.started": "2022-08-21T13:55:43.646811Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a202ced55a1240329d610a5c1b7f7d9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1600000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "data.text = data.text.progress_apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "b71de311-221a-4a38-a0e6-69d5c961a717",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-21T14:14:07.480430Z",
     "iopub.status.busy": "2022-08-21T14:14:07.480430Z",
     "iopub.status.idle": "2022-08-21T14:17:50.060254Z",
     "shell.execute_reply": "2022-08-21T14:17:49.962377Z",
     "shell.execute_reply.started": "2022-08-21T14:14:07.480430Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoded_input = tokenizer(\n",
    "    data.text.to_list(),\n",
    "    return_tensors=\"pt\",\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2772990a-f42c-4088-861e-96137ad0058c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-21T14:26:19.437578Z",
     "iopub.status.busy": "2022-08-21T14:26:19.437578Z",
     "iopub.status.idle": "2022-08-21T14:26:20.365572Z",
     "shell.execute_reply": "2022-08-21T14:26:20.359579Z",
     "shell.execute_reply.started": "2022-08-21T14:26:19.437578Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model(\n",
    "    input_ids=encoded_input[\"input_ids\"][:10, :],\n",
    "    attention_mask=encoded_input[\"attention_mask\"][:2, :],\n",
    ").logits[:, [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "ac2aff30-24eb-4d2d-890a-9e4d1d1f5a9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-04T19:24:07.026704Z",
     "iopub.status.busy": "2022-08-04T19:24:07.025712Z",
     "iopub.status.idle": "2022-08-04T19:24:07.038693Z",
     "shell.execute_reply": "2022-08-04T19:24:07.037712Z",
     "shell.execute_reply.started": "2022-08-04T19:24:07.025712Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': tensor([0, 0, 0, 0, 0]),\n",
       " 'ids': tensor([1467810369, 1467810672, 1467810917, 1467811184, 1467811193]),\n",
       " 'date': ['Mon Apr 06 22:19:45 PDT 2009',\n",
       "  'Mon Apr 06 22:19:49 PDT 2009',\n",
       "  'Mon Apr 06 22:19:53 PDT 2009',\n",
       "  'Mon Apr 06 22:19:57 PDT 2009',\n",
       "  'Mon Apr 06 22:19:57 PDT 2009'],\n",
       " 'flag': ['NO_QUERY', 'NO_QUERY', 'NO_QUERY', 'NO_QUERY', 'NO_QUERY'],\n",
       " 'user': ['_TheSpecialOne_', 'scotthamilton', 'mattycus', 'ElleCTF', 'Karoli'],\n",
       " 'text': [\"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\",\n",
       "  \"is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!\",\n",
       "  '@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds',\n",
       "  'my whole body feels itchy and like its on fire ',\n",
       "  \"@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there. \"]}"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import ClassLabel, Dataset\n",
    "\n",
    "model(\n",
    "    next(\n",
    "        iter(\n",
    "            DataLoader(Dataset.from_pandas(data.head()), batch_size=256, shuffle=False)\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
